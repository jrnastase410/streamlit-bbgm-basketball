{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-27T00:43:09.785705500Z",
     "start_time": "2024-02-27T00:43:08.919996400Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "import json\n",
    "\n",
    "import plotly.io as pio\n",
    "import re\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "pio.renderers.default = \"browser\""
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_salary_cap_events():\n",
    "    ## Load json file from downloads\n",
    "    with open('C:/Users/jrnas/Downloads/BBGM_League_1_2220_free_agency(1).json', encoding='latin') as f:\n",
    "        r_json = json.load(f)\n",
    "\n",
    "    return pd.DataFrame([(x['season'], x['text']) for x in r_json['events'] if 'An inflation rate of' in x['text']],\n",
    "                        columns=['season', 'text'])\n",
    "\n",
    "\n",
    "def extract_values(text):\n",
    "    # Pattern for inflation rate\n",
    "    inflation_pattern = r\"(\\d+(\\.\\d+)?)%\"\n",
    "    # Pattern for salary cap\n",
    "    salary_cap_pattern = r\"\\$(\\d+(\\.\\d+)?[MB]?)\"\n",
    "\n",
    "    # Search for the patterns\n",
    "    inflation_match = re.search(inflation_pattern, text)\n",
    "    salary_cap_match = re.search(salary_cap_pattern, text)\n",
    "\n",
    "    # Extract the matched values\n",
    "    inflation_rate = float(inflation_match.group(1)) if inflation_match else None\n",
    "    salary_cap = salary_cap_match.group(1) if salary_cap_match else None\n",
    "\n",
    "    return inflation_rate, salary_cap\n",
    "\n",
    "\n",
    "def convert_salary_cap(salary_cap):\n",
    "    if salary_cap.endswith('M'):\n",
    "        return float(salary_cap[:-1])\n",
    "    elif salary_cap.endswith('B'):\n",
    "        return float(salary_cap[:-1]) * 1000\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_salary_cap():\n",
    "    inf_df = get_salary_cap_events()\n",
    "    inf_df['inf_rate'], inf_df['salary_cap'] = zip(*inf_df['text'].apply(extract_values))\n",
    "    inf_df['salary_cap'] = inf_df['salary_cap'].apply(convert_salary_cap)\n",
    "    inf_df = inf_df[['season', 'inf_rate', 'salary_cap']]\n",
    "    ## Add a row for 2023\n",
    "    inf_df = pd.concat(\n",
    "        [pd.DataFrame({'season': 2023, 'inf_rate': 0, 'salary_cap': 136}, index=[0]), inf_df]).reset_index(\n",
    "        drop=True)\n",
    "    ## Set up dictionary\n",
    "    return inf_df.set_index('season').to_dict()['salary_cap']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T00:43:09.797987500Z",
     "start_time": "2024-02-27T00:43:09.790128200Z"
    }
   },
   "id": "de8ac6c1b765835f",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "salary_cap = get_salary_cap()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T00:43:10.764554200Z",
     "start_time": "2024-02-27T00:43:09.792674800Z"
    }
   },
   "id": "4b98105db065f320",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('C:/Users/jrnas/Downloads/BBGM_League_1_2220_free_agency.json', encoding='latin') as f:\n",
    "    r_json = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T00:43:17.875388200Z",
     "start_time": "2024-02-27T00:43:10.766743900Z"
    }
   },
   "id": "1ba2a26e3c4942fd",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14724/14724 [00:00<00:00, 27900.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate over the list of players\n",
    "for player in tqdm(r_json['players']):\n",
    "    # Iterate over the ratings of the current player\n",
    "    for rating in player['stats']:\n",
    "        # Create a new dictionary that includes 'pid', 'firstName', 'lastName' and the rating\n",
    "        row = {\n",
    "            'pid': player['pid']\n",
    "        }\n",
    "        row.update(rating)\n",
    "        # Append the dictionary to the list\n",
    "        data.append(row)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "stats_df = (\n",
    "    pd.DataFrame(data)\n",
    "    .convert_dtypes(dtype_backend='pyarrow')\n",
    ")\n",
    "\n",
    "stats_df = stats_df[(stats_df.season.between(2024, 2220)) & (stats_df.playoffs == False)].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T00:43:21.206449600Z",
     "start_time": "2024-02-27T00:43:17.878546400Z"
    }
   },
   "id": "f294ca8b2e190cbf",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14724/14724 [00:00<00:00, 70834.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate over the list of players\n",
    "for player in tqdm(r_json['players']):\n",
    "    # Iterate over the ratings of the current player\n",
    "    for rating in player['ratings']:\n",
    "        # Create a new dictionary that includes 'pid', 'firstName', 'lastName' and the rating\n",
    "        row = {\n",
    "            'pid': player['pid'],\n",
    "            'firstName': player['firstName'],\n",
    "            'lastName': player['lastName'],\n",
    "            'born': player['born']['year'],\n",
    "        }\n",
    "        row.update(rating)\n",
    "        # Append the dictionary to the list\n",
    "        data.append(row)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "ratings_df = (\n",
    "    pd.DataFrame(data)\n",
    "    .convert_dtypes(dtype_backend='pyarrow')\n",
    "    .astype({'skills': 'string[pyarrow]'})\n",
    "    .assign(\n",
    "        age=lambda x: x.season - x.born,\n",
    "    )\n",
    ")\n",
    "\n",
    "ratings_df = ratings_df[ratings_df.season.between(2024, 2220)].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T00:43:22.229899900Z",
     "start_time": "2024-02-27T00:43:21.323282300Z"
    }
   },
   "id": "93d4e231782f3426",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14724/14724 [00:00<00:00, 340502.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate over the list of players\n",
    "for player in tqdm(r_json['players']):\n",
    "    # Iterate over the ratings of the current player\n",
    "    for rating in player['salaries']:\n",
    "        # Create a new dictionary that includes 'pid', 'firstName', 'lastName' and the rating\n",
    "        row = {\n",
    "            'pid': player['pid'],\n",
    "        }\n",
    "        row.update(rating)\n",
    "        # Append the dictionary to the list\n",
    "        data.append(row)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "salaries_df = (\n",
    "    pd.DataFrame(data)\n",
    "    .convert_dtypes(dtype_backend='pyarrow')\n",
    ")\n",
    "\n",
    "salaries_df = salaries_df[salaries_df.season.between(2024, 2220)].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T00:43:22.403763300Z",
     "start_time": "2024-02-27T00:43:22.267889700Z"
    }
   },
   "id": "4d990700b10f48fc",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = ratings_df.merge(\n",
    "    stats_df[['pid', 'season', 'tid', 'gp', 'gs', 'min', 'usgp', 'ortg', 'drtg', 'obpm', 'dbpm', 'ows', 'dws', 'vorp',\n",
    "              'ewa']],\n",
    "    on=['pid', 'season'], how='left').merge(\n",
    "    salaries_df[['pid', 'season', 'amount']].rename(columns={'amount': 'salary'}), on=['pid', 'season'], how='left')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T00:43:22.541501400Z",
     "start_time": "2024-02-27T00:43:22.392338400Z"
    }
   },
   "id": "f5395c396b335e5",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['vorp_norm'] = (df['vorp'] / df['min']) * (32 * 82)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T00:43:22.557074900Z",
     "start_time": "2024-02-27T00:43:22.542688500Z"
    }
   },
   "id": "51763d4ac524764f",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_df = df[(df['min'] > 10) & (~df['vorp_norm'].isna())].reset_index(drop=True)\n",
    "test_df['vorp_norm_wt'] = test_df['vorp_norm'] * test_df['min']\n",
    "agg_df = test_df.groupby('ovr')[['vorp_norm_wt', 'min']].sum().reset_index()\n",
    "agg_df['vorp_norm'] = agg_df['vorp_norm_wt'] / agg_df['min']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T00:43:22.595552700Z",
     "start_time": "2024-02-27T00:43:22.549957900Z"
    }
   },
   "id": "3438719698f7da4f",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "under_over = 56.064\n",
    "\n",
    "model_df_under = agg_df[agg_df['ovr'] <= under_over].reset_index(drop=True)\n",
    "poly_under = np.polyfit(model_df_under['ovr'], model_df_under['vorp_norm'], 1)\n",
    "\n",
    "model_df_over = agg_df[agg_df['ovr'] > under_over].reset_index(drop=True)\n",
    "poly_over = np.polyfit(model_df_over['ovr'], model_df_over['vorp_norm'], 1)\n",
    "\n",
    "df['vorp_under'] = np.polyval(poly_under, df['ovr'])\n",
    "df['vorp_over'] = np.polyval(poly_over, df['ovr'])\n",
    "df['vorp_pred'] = np.where(\n",
    "    df['ovr'] <= under_over,\n",
    "    df['vorp_under'],\n",
    "    df['vorp_over']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T00:43:22.612942900Z",
     "start_time": "2024-02-27T00:43:22.593320300Z"
    }
   },
   "id": "892fa998a81a39fe",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['cvorp'] = df['vorp'].clip(0, )\n",
    "df['vorp_pct'] = df['vorp_pred'].clip(0, ) / df.groupby('season').cvorp.sum().mean()\n",
    "df['vorp_pct_cap'] = df['vorp_pct'] * 30"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T00:43:22.636185200Z",
     "start_time": "2024-02-27T00:43:22.606334800Z"
    }
   },
   "id": "e24ec4e1b9e87644",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T00:43:22.637216600Z",
     "start_time": "2024-02-27T00:43:22.624150100Z"
    }
   },
   "id": "36a99117666a6a06",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "### Growth"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T00:43:22.637382700Z",
     "start_time": "2024-02-27T00:43:22.627171Z"
    }
   },
   "id": "a5cd47233dbb5836",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(['pid', 'season'], keep='first').reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T00:43:22.703103100Z",
     "start_time": "2024-02-27T00:43:22.631653500Z"
    }
   },
   "id": "e127db17d9928d76",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['ovr+'] = df.groupby('pid')['ovr'].shift(-1) - df['ovr']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T00:43:22.722682800Z",
     "start_time": "2024-02-27T00:43:22.705192200Z"
    }
   },
   "id": "46cfe936709ae695",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "kde_dict = dict()\n",
    "\n",
    "for age in range(19, 36):\n",
    "    kde_dict[age] = dict()\n",
    "    kde_dict[age]['data'] = df[df.age == age]['ovr+'].dropna().values\n",
    "    kde_dict[age]['kde'] = gaussian_kde(kde_dict[age]['data'])\n",
    "    \n",
    "kde_dict[18] = kde_dict[19]\n",
    "\n",
    "for age in range(36, 60):\n",
    "    kde_dict[age] = kde_dict[35]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T00:43:22.834299Z",
     "start_time": "2024-02-27T00:43:22.715686300Z"
    }
   },
   "id": "60c8c67041f1507c",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import numpy as np\n",
    "\n",
    "def convolve_distributions(kdes):\n",
    "    # Generate x values that cover the range of all KDEs\n",
    "    x = np.linspace(-100, 100, 1000)\n",
    "\n",
    "    # Initialize the convolved density as the density of the first KDE\n",
    "    y_convolved = kdes[0](x)\n",
    "\n",
    "    # Iterate over the rest of the KDEs\n",
    "    for kde in kdes[1:]:\n",
    "        # Calculate the density of the current KDE\n",
    "        y = kde(x)\n",
    "\n",
    "        # Perform the convolution\n",
    "        y_convolved = signal.convolve(y_convolved, y, mode='same')\n",
    "\n",
    "        # Normalize the result\n",
    "        y_convolved /= np.trapz(y_convolved, x)  # Use trapezoidal rule to approximate the integral\n",
    "\n",
    "    return x, y_convolved"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T00:43:22.941969900Z",
     "start_time": "2024-02-27T00:43:22.837497100Z"
    }
   },
   "id": "4c0db0e6689f5e96",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys([19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 18, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kde_dict.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T00:43:22.943053400Z",
     "start_time": "2024-02-27T00:43:22.938149Z"
    }
   },
   "id": "32613337b14aa2b6",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Use the function with two KDEs from your dictionary\n",
    "x_new, y_new = convolve_distributions([\n",
    "    kde_dict[19]['kde'], \n",
    "    kde_dict[20]['kde'],\n",
    "    kde_dict[21]['kde'],\n",
    "    kde_dict[22]['kde'],\n",
    "])\n",
    "# Normalize the result\n",
    "y_new /= np.trapz(y_new, x_new)  # Use trapezoidal rule to approximate the integral"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T00:43:23.540685700Z",
     "start_time": "2024-02-27T00:43:22.943053400Z"
    }
   },
   "id": "359fa65d4c30dfd8",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3/28 [00:21<03:02,  7.30s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m dicts_to_compile \u001B[38;5;241m=\u001B[39m [kde_dict[age][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mkde\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m age \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(age, age \u001B[38;5;241m+\u001B[39m years_in_adv)]\n\u001B[0;32m      6\u001B[0m prog_dict[age][years_in_adv] \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m----> 7\u001B[0m prog_dict[age][years_in_adv][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx\u001B[39m\u001B[38;5;124m'\u001B[39m], prog_dict[age][years_in_adv][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mconvolve_distributions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdicts_to_compile\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[18], line 14\u001B[0m, in \u001B[0;36mconvolve_distributions\u001B[1;34m(kdes)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Iterate over the rest of the KDEs\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m kde \u001B[38;5;129;01min\u001B[39;00m kdes[\u001B[38;5;241m1\u001B[39m:]:\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;66;03m# Calculate the density of the current KDE\u001B[39;00m\n\u001B[1;32m---> 14\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mkde\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;66;03m# Perform the convolution\u001B[39;00m\n\u001B[0;32m     17\u001B[0m     y_convolved \u001B[38;5;241m=\u001B[39m signal\u001B[38;5;241m.\u001B[39mconvolve(y_convolved, y, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msame\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\BBGM\\Lib\\site-packages\\scipy\\stats\\_kde.py:271\u001B[0m, in \u001B[0;36mgaussian_kde.evaluate\u001B[1;34m(self, points)\u001B[0m\n\u001B[0;32m    268\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[0;32m    270\u001B[0m output_dtype, spec \u001B[38;5;241m=\u001B[39m _get_output_dtype(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcovariance, points)\n\u001B[1;32m--> 271\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mgaussian_kernel_estimate\u001B[49m\u001B[43m[\u001B[49m\u001B[43mspec\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweights\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpoints\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcho_cov\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_dtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    275\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result[:, \u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "prog_dict = {}\n",
    "for age in tqdm(range(df.age.min(), df.age.max() + 1)):\n",
    "    prog_dict[age] = {}\n",
    "    for years_in_adv in range(1, 10):\n",
    "        dicts_to_compile = [kde_dict[age]['kde'] for age in range(age, age + years_in_adv)]\n",
    "        prog_dict[age][years_in_adv] = {}\n",
    "        prog_dict[age][years_in_adv]['x'], prog_dict[age][years_in_adv]['y'] = convolve_distributions(dicts_to_compile)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T00:43:45.500602400Z",
     "start_time": "2024-02-27T00:43:23.528371Z"
    }
   },
   "id": "bc15e4f1b0a48fce",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "prog_df_list = []\n",
    "for age in range(df.age.min(), df.age.max() + 1):\n",
    "    ## Create a df for each age, a column with values ranging from -100 to 100 and a column with the density for each years_in_adv\n",
    "    prog_df = pd.DataFrame()\n",
    "    for years_in_adv in range(1, 10):\n",
    "        temp_df = pd.DataFrame({'x': prog_dict[age][years_in_adv]['x'], f'y_{years_in_adv}': prog_dict[age][years_in_adv]['y']})\n",
    "        if years_in_adv > 1:\n",
    "            temp_df = temp_df.drop('x', axis=1)\n",
    "        prog_df = pd.concat([prog_df, temp_df], axis=1)\n",
    "    prog_df_list.append(prog_df.assign(age=age))\n",
    "prog_df = pd.concat(prog_df_list, axis=0).reset_index(drop=True)\n",
    "prog_df.to_parquet('../constants/progression.parquet')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-27T00:43:45.502923200Z"
    }
   },
   "id": "a99b9ad30de5882b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_df = pd.read_parquet('../constants/progression.parquet')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T00:43:47.074971100Z",
     "start_time": "2024-02-27T00:43:47.019619300Z"
    }
   },
   "id": "55617e2050559aec",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "-0.6694764862466687"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(\n",
    "    test_df[test_df.age == 26]['x'].values,\n",
    "    test_df[test_df.age == 26]['y_1'].values\n",
    ") / np.sum(test_df[test_df.age == 26]['y_1'].values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T00:44:11.003826700Z",
     "start_time": "2024-02-27T00:44:10.981736700Z"
    }
   },
   "id": "5c879e7301431a0d",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T00:43:45.514759Z",
     "start_time": "2024-02-27T00:43:45.508028200Z"
    }
   },
   "id": "754c7c4b4a8b1f79"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
